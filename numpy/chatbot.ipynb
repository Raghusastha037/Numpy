{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/232.6 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 225.3/232.6 kB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.50.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.1.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.10.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.4)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.11.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Collecting typing-extensions<5,>=4.4.0 (from streamlit)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 0.0/67.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.3/67.3 kB 3.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.62.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.3-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.0/43.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: certifi in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.75.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Using cached protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->chromadb) (2.17.2)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.5)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ------------------------ -------------- 593.9/948.6 kB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 948.6/948.6 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading chromadb-1.1.0-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "   ---------------------------------------- 0.0/19.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/19.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.3/19.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.4/19.8 MB 24.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 4.8/19.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 6.2/19.8 MB 24.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 7.6/19.8 MB 25.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 8.6/19.8 MB 24.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.6/19.8 MB 24.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 10.6/19.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 11.9/19.8 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 13.4/19.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 14.8/19.8 MB 25.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.9/19.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 17.5/19.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 18.7/19.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.8/19.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.8/19.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.8/19.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.8/19.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.8/19.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.8/19.8 MB 17.2 MB/s eta 0:00:00\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 150.9/150.9 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.0-cp311-cp311-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 204.3/204.3 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.2/1.9 MB 25.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 30.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 20.5 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 447.5/447.5 kB 14.1 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
      "   ---------------------------------------- 0.0/386.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 386.3/386.3 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.2.0-cp311-cp311-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.23.0-cp311-cp311-win_amd64.whl (13.4 MB)\n",
      "   ---------------------------------------- 0.0/13.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.9/13.4 MB 58.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.1/13.4 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.4/13.4 MB 31.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.1/13.4 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.2/13.4 MB 30.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.7/13.4 MB 30.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.0/13.4 MB 30.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.4/13.4 MB 29.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.9/13.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.7/13.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.3/13.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.4/13.4 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.7/65.7 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.5/72.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.75.0-cp311-cp311-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.6 MB 21.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.0/4.6 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.0/4.6 MB 19.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.1/4.6 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.6/4.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.6/4.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.9/131.9 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/208.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 208.0/208.0 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading orjson-3.11.3-cp311-cp311-win_amd64.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.4/131.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pybase64-1.4.2-cp311-cp311-win_amd64.whl (35 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.8/158.8 kB 9.3 MB/s eta 0:00:00\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.1 MB 30.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.5/2.7 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 28.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 18.9 MB/s eta 0:00:00\n",
      "Using cached typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.5/294.5 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 299.1/299.1 kB 9.3 MB/s eta 0:00:00\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 88.6/88.6 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB 1.4 MB/s eta 0:00:00\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.1.0-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 292.6/292.6 kB 17.6 MB/s eta 0:00:00\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 176.8/176.8 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "   ---------------------------------------- 0.0/506.2 kB ? eta -:--:--\n",
      "   --------------------------------------  501.8/506.2 kB 30.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 506.2/506.2 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.1/6.3 MB 36.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.7/6.3 MB 34.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.9/6.3 MB 31.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.1/6.3 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 28.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 28.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 21.2 MB/s eta 0:00:00\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 81.9/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------  532.5/536.2 kB 34.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 536.2/536.2 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.2/83.2 kB 4.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=e15cb639ef40bc06b632ef112850a0b65e42caa2cec15a30f22e5b39e35ac511\n",
      "  Stored in directory: c:\\users\\raghu\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, durationpy, zstandard, zipp, websockets, websocket-client, typing-extensions, sympy, sniffio, shellingham, PyYAML, python-dotenv, pyreadline3, pyproject_hooks, pybase64, protobuf, overrides, orjson, mmh3, mdurl, jsonpointer, jiter, importlib-resources, httptools, h11, greenlet, fsspec, filelock, distro, bcrypt, backoff, annotated-types, uvicorn, typing-inspection, SQLAlchemy, requests-toolbelt, pydantic-core, posthog, opentelemetry-proto, markdown-it-py, jsonpatch, importlib-metadata, humanfriendly, huggingface-hub, httpcore, grpcio, googleapis-common-protos, build, anyio, watchfiles, tokenizers, rich, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, kubernetes, httpx, coloredlogs, typer, opentelemetry-semantic-conventions, openai, onnxruntime, langsmith, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, chromadb\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.62.0\n",
      "    Uninstalling grpcio-1.62.0:\n",
      "      Successfully uninstalled grpcio-1.62.0\n",
      "Successfully installed PyYAML-6.0.3 SQLAlchemy-2.0.43 annotated-types-0.7.0 anyio-4.11.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.1.0 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 filelock-3.19.1 fsspec-2025.9.0 googleapis-common-protos-1.70.0 greenlet-3.2.4 grpcio-1.75.0 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 huggingface-hub-0.35.1 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jiter-0.11.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-33.1.0 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.31 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 onnxruntime-1.23.0 openai-1.109.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 orjson-3.11.3 overrides-7.7.0 posthog-5.4.0 protobuf-6.32.1 pybase64-1.4.2 pydantic-2.11.9 pydantic-core-2.33.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 requests-toolbelt-1.0.0 rich-14.1.0 shellingham-1.5.4 sniffio-1.3.1 sympy-1.14.0 tokenizers-0.22.1 typer-0.19.2 typing-extensions-4.15.0 typing-inspection-0.4.1 uvicorn-0.37.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 zipp-3.23.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit langchain openai chromadb PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 13:57:58.248 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.250 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.330 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\raghu\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-09-26 13:57:58.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.335 Session state does not function when running a script without `streamlit run`\n",
      "2025-09-26 13:57:58.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "C:\\Users\\raghu\\AppData\\Local\\Temp\\ipykernel_10640\\1281892026.py:147: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  st.session_state[\"embeddings\"] = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
      "2025-09-26 13:57:58.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-26 13:57:58.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"embeddings\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:469\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:517\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 152\u001b[0m\n\u001b[0;32m    149\u001b[0m         st\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to initialize embeddings. Make sure OPENAI_API_KEY is set and langchain/openai packages installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m         st\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m--> 152\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    153\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m build_or_load_vectorstore(embeddings)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# If user asked to build index from uploaded files\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:101\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     99\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[0;32m    100\u001b[0m require_valid_user_key(key)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:104\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\raghu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:471\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"embeddings\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "from typing import List, Optional\n",
    "\n",
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "PERSIST_DIR = \"./chroma_resume_db\"\n",
    "CHUNK_SIZE = 800\n",
    "CHUNK_OVERLAP = 120\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"  # OpenAI embedding model name (adjustable)\n",
    "LLM_MODEL = \"gpt-4o-mini\"  # example LLM (adjustable)\n",
    "\n",
    "# ---------------------\n",
    "# Helpers\n",
    "# ---------------------\n",
    "\n",
    "def pdf_to_text(file_path: str) -> str:\n",
    "    \"\"\"Extract text from PDF using PyPDF2 (works for many simple PDFs).\"\"\"\n",
    "    text_chunks = []\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text_chunks.append(page_text)\n",
    "    except Exception as e:\n",
    "        st.warning(f\"PDF parsing error for {file_path}: {e}\")\n",
    "    return \"\\n\".join(text_chunks)\n",
    "\n",
    "\n",
    "def extract_candidate_name(text: str) -> Optional[str]:\n",
    "    \"\"\"Heuristic extraction of candidate name from resume text.\n",
    "    Strategy:\n",
    "      - Look for lines beginning with 'Name' or 'Candidate' (common headers)\n",
    "      - Otherwise use the first non-empty line that looks like a name (no @, no 'linkedin', not too long)\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "    # 1) look for explicit labels\n",
    "    for ln in lines[:20]:\n",
    "        m = re.match(r\"^(?:name|candidate|full name)[:\\-\\s]{0,3}(.+)$\", ln, flags=re.I)\n",
    "        if m:\n",
    "            candidate = m.group(1).strip()\n",
    "            candidate = re.sub(r\"[|,].*\", \"\", candidate).strip()\n",
    "            if 2 <= len(candidate) <= 60:\n",
    "                return candidate\n",
    "\n",
    "    # 2) fallback: first line that looks like a name\n",
    "    for ln in lines[:10]:\n",
    "        if \"@\" in ln or \"linkedin\" in ln.lower() or \"www.\" in ln.lower() or re.search(r\"\\d\", ln):\n",
    "            continue\n",
    "        # allow shortish lines with letters and spaces\n",
    "        if 2 <= len(ln) <= 50 and re.match(r\"^[A-Za-z .'-]+$\", ln):\n",
    "            return ln\n",
    "\n",
    "    # 3) last fallback: filename or None handled outside\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_or_load_vectorstore(embeddings: OpenAIEmbeddings, persist_dir: str = PERSIST_DIR) -> Chroma:\n",
    "    \"\"\"Load existing Chroma DB if present, otherwise create an empty one.\"\"\"\n",
    "    if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "        vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "    else:\n",
    "        vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "def index_resumes(pdf_files: List[str], embeddings: OpenAIEmbeddings, persist_dir: str = PERSIST_DIR):\n",
    "    \"\"\"Parse PDFs, split into chunks, and add to Chroma with metadata (source filename, candidate_name).\n",
    "    pdf_files: list of file paths\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    vectordb = build_or_load_vectorstore(embeddings, persist_dir)\n",
    "\n",
    "    added = 0\n",
    "    for path in pdf_files:\n",
    "        text = pdf_to_text(path)\n",
    "        if not text.strip():\n",
    "            st.warning(f\"No text found in {os.path.basename(path)} - skipping\")\n",
    "            continue\n",
    "\n",
    "        candidate_name = extract_candidate_name(text) or os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        metadatas = [{\n",
    "            \"source\": os.path.basename(path),\n",
    "            \"candidate_name\": candidate_name,\n",
    "        } for _ in chunks]\n",
    "\n",
    "        vectordb.add_texts(texts=chunks, metadatas=metadatas)\n",
    "        added += len(chunks)\n",
    "\n",
    "    vectordb.persist()\n",
    "    return added\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Streamlit UI\n",
    "# ---------------------\n",
    "\n",
    "st.set_page_config(page_title=\"RAG Resume Search\", layout=\"wide\")\n",
    "st.title(\"RAG Resume Search — LangChain + Streamlit\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = []\n",
    "\n",
    "# Sidebar: uploader + controls\n",
    "with st.sidebar:\n",
    "    st.header(\"Index Resumes\")\n",
    "    uploaded_files = st.file_uploader(\"Upload PDF resumes (multiple)\", type=[\"pdf\"], accept_multiple_files=True)\n",
    "\n",
    "    build_index = st.button(\"Build / Update Index from uploaded files\")\n",
    "    clear_index = st.button(\"Clear stored index (delete DB)\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.header(\"Search Options\")\n",
    "    candidate_query = st.text_input(\"Search by candidate name (exact or partial)\")\n",
    "    question = st.text_input(\"Or ask a question about selected candidate(s) / all resumes\")\n",
    "\n",
    "    llm_temperature = st.slider(\"LLM temperature\", 0.0, 1.0, 0.1, 0.05)\n",
    "\n",
    "# Handle clear index\n",
    "if clear_index:\n",
    "    if os.path.exists(PERSIST_DIR):\n",
    "        import shutil\n",
    "\n",
    "        shutil.rmtree(PERSIST_DIR)\n",
    "        st.success(\"Cleared persistent vectorstore\")\n",
    "    else:\n",
    "        st.info(\"No persistent database found to delete\")\n",
    "\n",
    "# Initialize embeddings and vectorstore\n",
    "if \"embeddings\" not in st.session_state:\n",
    "    try:\n",
    "        st.session_state[\"embeddings\"] = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    except Exception as e:\n",
    "        st.error(\"Failed to initialize embeddings. Make sure OPENAI_API_KEY is set and langchain/openai packages installed.\")\n",
    "        st.stop()\n",
    "\n",
    "embeddings = st.session_state[\"embeddings\"]\n",
    "vectordb = build_or_load_vectorstore(embeddings)\n",
    "\n",
    "# If user asked to build index from uploaded files\n",
    "if build_index:\n",
    "    if not uploaded_files:\n",
    "        st.warning(\"Please upload one or more PDF resumes first.\")\n",
    "    else:\n",
    "        # Save uploaded files to temporary files so PyPDF2 can read them\n",
    "        tmp_paths = []\n",
    "        for up in uploaded_files:\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp:\n",
    "                tmp.write(up.getbuffer())\n",
    "                tmp_paths.append(tmp.name)\n",
    "\n",
    "        with st.spinner(\"Indexing resumes — this can take a few minutes depending on how many files you uploaded\"):\n",
    "            added_chunks = index_resumes(tmp_paths, embeddings)\n",
    "        st.success(f\"Indexed {len(tmp_paths)} files, added ~{added_chunks} chunks to vectorstore\")\n",
    "\n",
    "# Candidate filter button\n",
    "search_by_candidate = st.button(\"Find candidate\")\n",
    "\n",
    "# Prepare retriever and conversational chain\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model_name=LLM_MODEL, temperature=llm_temperature)\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "\n",
    "# If user wants to find candidate by name\n",
    "selected_candidate_sources = None\n",
    "if search_by_candidate:\n",
    "    if not candidate_query:\n",
    "        st.warning(\"Enter a candidate name or partial name to search by metadata\")\n",
    "    else:\n",
    "        # use chroma's metadata filter ability via similarity_search_with_relevance_scores and filtering\n",
    "        # Since langchain Chroma allows passing a filter dict to similarity_search, we'll try that\n",
    "        try:\n",
    "            # partial match: find any candidate_name containing the query (case-insensitive)\n",
    "            # Chroma doesn't support substring filters; instead we'll fetch candidates by searching for the query as text\n",
    "            # then filter by metadata client-side\n",
    "            hits = vectordb.similarity_search(candidate_query, k=20)\n",
    "            filtered = [doc for doc in hits if candidate_query.lower() in doc.metadata.get(\"candidate_name\", \"\").lower()]\n",
    "\n",
    "            if not filtered:\n",
    "                st.info(\"No candidate matched by metadata. Showing top semantic matches instead.\")\n",
    "                filtered = hits\n",
    "\n",
    "            # collect distinct candidate names and sources\n",
    "            candidates = {}\n",
    "            for d in filtered:\n",
    "                key = (d.metadata.get(\"candidate_name\"), d.metadata.get(\"source\"))\n",
    "                if key not in candidates:\n",
    "                    candidates[key] = d\n",
    "\n",
    "            st.session_state.setdefault(\"last_candidate_hits\", [])\n",
    "            st.session_state[\"last_candidate_hits\"] = list(candidates.keys())\n",
    "\n",
    "            st.write(\"Found candidates (candidate_name, source):\")\n",
    "            for idx, (cn, src) in enumerate(candidates.keys()):\n",
    "                st.write(f\"{idx+1}. {cn} — {src}\")\n",
    "\n",
    "            selected_candidate_sources = [src for (_cn, src) in candidates.keys()]\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error when searching vectorstore: {e}\")\n",
    "\n",
    "# If the user types a question or chooses a candidate, run the conversational QA\n",
    "if st.button(\"Ask\"):\n",
    "    if not question:\n",
    "        st.warning(\"Type a question in the 'Or ask a question' field first.\")\n",
    "    else:\n",
    "        # if the user specified a candidate name, we restrict the retriever to those sources\n",
    "        if candidate_query and st.session_state.get(\"last_candidate_hits\"):\n",
    "            # metadata-restricted retrieval: create a new retriever that filters by source files\n",
    "            candidate_sources = [src for (_cn, src) in st.session_state[\"last_candidate_hits\"]]\n",
    "\n",
    "            def filtered_retriever(query):\n",
    "                docs = []\n",
    "                for src in candidate_sources:\n",
    "                    hits = vectordb.similarity_search(query, k=5)\n",
    "                    src_hits = [d for d in hits if d.metadata.get(\"source\") == src]\n",
    "                    docs.extend(src_hits)\n",
    "                return docs\n",
    "\n",
    "            # fallback: use the normal chain but with prefiltered docs passed as \"retriever\" is harder to adapt.\n",
    "            # Simpler approach: build a temporary in-memory retriever by creating embeddings for the question and\n",
    "            # performing similarity_search on the main vectordb then filtering by source.\n",
    "            hits = vectordb.similarity_search(question, k=8)\n",
    "            filtered_hits = [d for d in hits if d.metadata.get(\"source\") in candidate_sources]\n",
    "            if not filtered_hits:\n",
    "                st.info(\"No matching chunks found for that candidate. Showing general results instead.\")\n",
    "                filtered_hits = hits\n",
    "\n",
    "            # Prepare context text for LLM summarization\n",
    "            context_text = \"\\n\\n\".join([d.page_content for d in filtered_hits[:6]])\n",
    "            prompt = f\"You are given the following resume excerpts:\\n\\n{context_text}\\n\\nAnswer the question concisely:\\n{question}\"\n",
    "            response = llm.call_as_llm(prompt) if hasattr(llm, \"call_as_llm\") else llm.generate([prompt])\n",
    "\n",
    "            # llm.call_as_llm compatibility handling\n",
    "            if isinstance(response, str):\n",
    "                answer = response\n",
    "            else:\n",
    "                try:\n",
    "                    # langchain newer API returns an LLMResult; grab text\n",
    "                    answer = response.generations[0][0].text\n",
    "                except Exception:\n",
    "                    answer = str(response)\n",
    "\n",
    "            st.markdown(\"**Answer:**\")\n",
    "            st.write(answer)\n",
    "        else:\n",
    "            # general question across all resumes\n",
    "            with st.spinner(\"Running RAG retrieval + LLM...\"):\n",
    "                result = qa_chain({\"question\": question, \"chat_history\": []})\n",
    "            st.markdown(\"**Answer:**\")\n",
    "            st.write(result.get(\"answer\"))\n",
    "\n",
    "# Show index stats\n",
    "try:\n",
    "    n_docs = vectordb._collection.count()\n",
    "    st.sidebar.write(f\"Indexed documents (approx chunks): {n_docs}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.write(\"Tips:\\n- Upload PDFs and click 'Build / Update Index'.\\n- Use 'Search by candidate name' to filter results by metadata.\\n- Use the Ask box to query a specific candidate or all resumes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06751940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.27)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: chromadb in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.50.0)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.109.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.4.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (1.75.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (0.19.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.32.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.3/76.3 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: certifi in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\raghu\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.35.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\raghu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.0/2.5 MB 31.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/75.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.0/75.0 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.11.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.4 kB ? eta -:--:--\n",
      "   --------------------------------------  880.6/884.4 kB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 884.4/884.4 kB 18.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "   ---------------------------------------- 0.0/453.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 453.3/453.3 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.6/48.6 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.0/44.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: requests, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, tiktoken, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-openai, langchain-community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.30 langchain-openai-0.3.33 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.11.0 requests-2.32.5 tiktoken-0.11.0 typing-inspect-0.9.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-community langchain-openai chromadb PyPDF2 streamlit tiktoken openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
